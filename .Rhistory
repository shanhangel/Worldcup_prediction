split <- strsplit(result1," ")
result2 <- list()
for (i in 1:16){
if (regexpr("PSO", result1[[i]])>0){
result2[i] <- split[[i]][length(split[[i]])-1]
}
else{
result2[i] <- split[[i]][1]
}
}
split1 <- strsplit(as.character(result2),":")
result3 <- list()
for (i in 1:16){
if (split1[[i]][1]>split1[[i]][2]){
result3[i]=1
}
else{
result3[i]=0
}
}
eliresult_2010 <- data.frame(home_team=home_team, away_team=away_team,
result=result,result3=as.numeric(result3))
## 组合小组赛和淘汰赛数据，以team作为index
final_result_2010 <- merge(eliresult_2010, gpresult_2010_2, by.x="home_team",
by.y="Team", sort=TRUE)
final_result_2010 <- merge(final_result_2010, gpresult_2010_2, by.x="away_team",
by.y="Team", sort=FALSE)
final_result_2010 <- data.frame(final_result_2010[,2], final_result_2010[,1],
final_result_2010[,4:18])
final_result_2010[18] <- "2010"
colnames(final_result_2010) <- c("Home", "Away", "Result", "Played_Home",
"Won_Home", "Draw_Home", "Lost_Home",
"Goals_For_Home", "Goals_Against_Home",
"Point_Home","Played_Away", "Won_Away",
"Draw_Away", "Lost_Away", "Goals_For_Away",
"Goals_Against_Away", "Point_Away", "Year")
write.csv(final_result_2010,"./worldcup_prediction/test.csv")
## 以1966-2006年世界杯结果为training dataset，进行过程中发现一些问题，1998-2010
## 年世界杯的参赛队伍为32支，比赛为64场，其中淘汰赛为第49-64场；1982-1994年参赛
## 队伍为24支，比赛为52场，其中淘汰赛为第37-52场；1966-1978年参赛队伍为16支，比
## 赛为38场，发现严重问题，78年以前小组赛分为两轮，第一轮晋级的，进入第二轮小组
## 赛，继续比赛争出现，因此无法利用小组赛信息作为淘汰赛的预测因素，因此training
## data只采用1982-2006年的数据。 %>_<%
## 建立function，以处理testing data的方法，建立training dataset
create_train_data <- function(Url){
web <- htmlTreeParse(Url, useInternal=TRUE)
year <- substr(Url, nchar(Url)-22, nchar(Url)-19)
if (Url%in%c(Url_2006, Url_2002, Url_1998)){
emi_index <- 49:64
}
else if (Url%in%c(Url_1994, Url_1990, Url_1986)){
emi_index <- 37:52
}
score <- xpathSApply(web, "//td[@class='c']", xmlValue)
team_name <- xpathSApply(web, "//td[@class='l']", xmlValue)
gpresult_1 <- matrix(score, ncol=7, byrow=TRUE)
gpresult_2 <- cbind(team_name, gpresult_1)
colnames(gpresult_2) <- c("Team", "Played", "Won", "Draw", "Lost",
"Goals For", "Goals Against", "Points")
home_team <- xpathSApply(web, "//td[@class='l homeTeam']",
xmlValue)[emi_index]
away_team <- xpathSApply(web, "//td[@class='r awayTeam']",
xmlValue)[emi_index]
result <- xpathSApply(web, "// td[@class='c ']", xmlValue)[emi_index]
result1 <- as.character(result)
split <- strsplit(result1," ")
result2 <- list()
for (i in 1:16){
if (regexpr("PSO", result1[[i]])>0){
result2[i] <- split[[i]][length(split[[i]])-1]
}
else{
result2[i] <- split[[i]][1]
}
}
split1 <- strsplit(as.character(result2),":")
result3 <- list()
for (i in 1:16){
if (split1[[i]][1]>split1[[i]][2]){
result3[i]=1
}
else{
result3[i]=0
}
}
eliresult <- data.frame(home_team=home_team, away_team=away_team,
result=result,result3=as.numeric(result3))
final_result <- merge(eliresult, gpresult_2, by.x="home_team",
by.y="Team", sort=TRUE)
final_result <- merge(final_result, gpresult_2, by.x="away_team",
by.y="Team", sort=FALSE)
final_result <- data.frame(final_result[,2], final_result[,1],
final_result[,4:18])
final_result[18] <- year
colnames(final_result) <- c("Home", "Away", "Result", "Played_Home",
"Won_Home", "Draw_Home", "Lost_Home",
"Goals_For_Home", "Goals_Against_Home",
"Point_Home", "Played_Away", "Won_Away",
"Draw_Away", "Lost_Away", "Goals_For_Away",
"Goals_Against_Away", "Point_Away", "Year")
filename=paste("training","_", year, sep="")
write.csv(final_result, paste("./worldcup_prediction/",filename,".csv",
sep=""))
}
Whole_Url <- c(Url_2006, Url_2002, Url_1998, Url_1994, Url_1990, Url_1986)
for (i in 1:6){
create_train_data(Whole_Url[i])
}
training_1986 <- read.csv("./worldcup_prediction/training_1986.csv")
training_1990 <- read.csv("./worldcup_prediction/training_1990.csv")
training_1994 <- read.csv("./worldcup_prediction/training_1994.csv")
training_1998 <- read.csv("./worldcup_prediction/training_1998.csv")
training_2002 <- read.csv("./worldcup_prediction/training_2002.csv")
training_2006 <- read.csv("./worldcup_prediction/training_2006.csv")
training <- rbind(training_1986, training_1990, training_1994, training_1998,
training_2002, training_2006)
write.csv(training, "./worldcup_prediction/training.csv")
## ============================================================================
## 3. Data Analysis
test <- read.csv("./worldcup_prediction/test.csv")
train_data <- data.frame(Result=as.factor(training$Result),
Played_Home=as.numeric(training$Played_Home),
Won_Home=as.numeric(training$Won_Home),
Draw_Home=as.numeric(training$Draw_Home),
Lost_Home=as.numeric(training$Lost_Home),
Goals_For_Home=as.numeric(training$Goals_For_Home),
Goals_Against_Home=as.numeric(training$Goals_Against_Home),
Point_Home=as.numeric(training$Point_Home),
Played_Away=as.numeric(training$Played_Away),
Won_Away=as.numeric(training$Won_Away),
Draw_Away=as.numeric(training$Draw_Away),
Lost_Away=as.numeric(training$Lost_Away),
Goals_For_Away=as.numeric(training$Goals_For_Away),
Goals_Against_Away=as.numeric(training$Goals_Against_Away),
Point_Away=as.numeric(training$Point_Away))
## SVD
par(mfrow=c(1,1))
svd1 <- svd(train_data[,c(3,4,6,7,10,11,13,14)])
plot(svd1$d, xlab = "Column", ylab = "Singular value", pch = 19)
dev.copy(png, "./worldcup_prediction/svd1.png")
dev.off()
## 可以看出各个因素中的共线性非常严重，分析原因如下，每队的出场数是一定的，胜负
## 平三场的总数是一定的，胜负结果确定以后积分也是一定的，因此，需要排除出场数
## "Played",负场数"Lost_Home"和"Lost_Away"，以及小组积分"Point_Home"和
## "Point_Away"
## 用train_data建立prediction model，用test进行模型筛选
## Try Logistic Regression Model
fit_LR <- glm(Result ~ ., data=train_data, family= "binomial")
prediction_LR <- predict(fit_LR, test)
prediction_LR[prediction_LR<0.5] <- 0
prediction_LR[prediction_LR>=0.5] <- 1
## Try Decision Tree Model
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(rpart)
fit_DT <- rpart(Result ~ ., data=train_data, method="class")
prediction_DT <- predict(fit_DT, test, type="class")
fancyRpartPlot(fit_DT)
dev.copy(pdf, "./worldcup_prediction/fit_DT.pdf")
dev.off()
## Try Random Forest Model
library(randomForest)
fit_RF <- randomForest(Result ~ ., data=train_data, importance=TRUE, ntree=100)
prediction_RF <- predict(fit_RF, test)
## Try Artificial Nerual Network Model
library(neuralnet)
fit_NN <- neuralnet(Result ~ ., data=train_data)
prediction_NN <- predict(fit_NN, test)
## 检查不同模型的预测效果，因为training data量比较小，所以比较简单的模型会
## 有比较好的结果，避免出现overfit，采用Logistic Regression.
model_check <- data.frame(test$Result, prediction_LR, prediction_DT,
prediction_RF)
print(fit_NN)
plot(fit_NN)
View(train_data)
View(test)
fit_LR <- glm(Result ~ Won_Home + Draw_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home +	Won_Away +	Draw_Away
+ Lost_Away	Goals_For_Away	Goals_Against_Away, data=train_data,
family= "binomial")
fit_LR <- glm(Result ~ Won_Home + Draw_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
family= "binomial")
prediction_LR <- predict(fit_LR, test)
prediction_LR[prediction_LR<0.5] <- 0
prediction_LR[prediction_LR>=0.5] <- 1
model_check <- data.frame(test$Result, prediction_LR)
View(model_check)
fit_DT <- rpart(Result ~ Won_Home + Draw_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
method="class")
prediction_DT <- predict(fit_DT, test, type="class")
fit_RF <- randomForest(Result ~ Won_Home + Draw_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
importance=TRUE, ntree=100)
prediction_RF <- predict(fit_RF, test)
library(neuralnet)
fit_NN <- neuralnet(Result ~ Won_Home + Draw_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data)
prediction_NN <- predict(fit_NN, test)
model_check <- data.frame(test$Result, prediction_LR, prediction_DT,
prediction_RF)
View(model_check)
library(randomForest)
fit_RF <- randomForest(Result ~ Won_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
importance=TRUE, ntree=100)
prediction_RF <- predict(fit_RF, test)
fit_DT <- rpart(Result ~ Won_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
method="class")
prediction_DT <- predict(fit_DT, test, type="class")
fit_LR <- glm(Result ~ Won_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
family= "binomial")
model_check <- data.frame(test$Result, prediction_LR, prediction_DT,
prediction_RF)
View(model_check)
View(training)
fit_RF <- randomForest(Result ~ Won_Home + Goals_For_Home
+ Goals_Against_Home + Point_Home + Won_Away + Draw_Away
+ Goals_For_Away + Goals_Against_Away, data=train_data,
importance=TRUE, ntree=1000)
prediction_RF <- predict(fit_RF, test)
model_check <- data.frame(test$Result, prediction_LR, prediction_DT,
prediction_RF)
View(model_check)
zhicheng <- read.csv("C:/Users/huangshan/Desktop/zhicheng.csv")
View(zhicheng)
zhicheng1 <- subset(zhicheng, zhicheng[,4]=="服务" & grepl("健康",zhicheng[,6])==1)
write.csv(zhicheng1,"zhicheng1.csv")
m = 57.3
h = 1.74.4
h = 174.4
a = 27
s = 5
B = 10*m + 6.26*h - 5*27 + 5
B
??read.csv
require(Rweibo)
？web.search.content
?web.search.content
require(Rweibo)
res<-web.search.content("热火",page=50,sleepmean=10,sleepsd=1)$Weibo ##page参数请自己设置
#2.分词
require(Rwordseg)
insertWords("热火")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
#3.词云展示
require(wordcloud)
dd<-tail(d,150)
op<-par(bg="lightyellow")
#grayLevels<-gray((dd$freq)/(max(dd$freq)+140))
#wordcloud(dd$word,dd$freq,colors=grayLevels)
rainbowLevels<-rainbow((dd$freq)/(max(dd$freq)-10))
wordcloud(dd$word,dd$freq,col=rainbow(length(d$freq)))
?api
??api
?sign_oauth1.0
n <- 5
pvals <- seq(0, 1, length = 1000)
plot(c(0, 1), c(0, 1.2), type = "n", frame = FALSE, xlab = "p", ylab = "likelihood")
text((0 : n) /n, 1.1, as.character(0 : n))
sapply(0 : n, function(x) {
phat <- x / n
if (x == 0) lines(pvals, ( (1 - pvals) / (1 - phat) )^(n-x), lwd = 3)
else if (x == n) lines(pvals, (pvals / phat) ^ x, lwd = 3)
else lines(pvals, (pvals / phat ) ^ x * ( (1 - pvals) / (1 - phat) ) ^ (n-x), lwd = 3)
}
)
?pbiom
pbionm
?pbinom
qnorm(.95, mean = 0, sd = 0)
qnorm(.95, mean = 1, sd = 2)
?ppos
require(Rweibo)
res<-web.search.content("世界杯",page=50,sleepmean=10,sleepsd=1)$Weibo ##page参数请自己设置
#2.分词
require(Rwordseg)
insertWords("世界杯")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
#3.词云展示
require(wordcloud)
dd<-tail(d,150)
op<-par(bg="lightyellow")
#grayLevels<-gray((dd$freq)/(max(dd$freq)+140))
#wordcloud(dd$word,dd$freq,colors=grayLevels)
rainbowLevels<-rainbow((dd$freq)/(max(dd$freq)-10))
wordcloud(dd$word,dd$freq,col=rainbow(length(d$freq)))
par(op)
1.96*75/10
1100+14.7
1100-14.7
require(Rweibo)
res<-web.search.content("研发创新平台",page=50,sleepmean=10,sleepsd=1)$Weibo ##page参数请自己设置
require(Rwordseg)
insertWords("研发创新平台")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
#3.词云展示
require(wordcloud)
dd<-tail(d,150)
op<-par(bg="lightyellow")
#grayLevels<-gray((dd$freq)/(max(dd$freq)+140))
#wordcloud(dd$word,dd$freq,colors=grayLevels)
rainbowLevels<-rainbow((dd$freq)/(max(dd$freq)-10))
wordcloud(dd$word,dd$freq,col=rainbow(length(d$freq)))
par(op)
require(Rweibo)
res<-web.search.content("宝洁",page=50,sleepmean=10,sleepsd=1)$Weibo ##page参数请自己设置
#2.分词
require(Rwordseg)
insertWords("宝洁")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
#3.词云展示
require(wordcloud)
dd<-tail(d,150)
op<-par(bg="lightyellow")
#grayLevels<-gray((dd$freq)/(max(dd$freq)+140))
#wordcloud(dd$word,dd$freq,colors=grayLevels)
rainbowLevels<-rainbow((dd$freq)/(max(dd$freq)-10))
wordcloud(dd$word,dd$freq,col=rainbow(length(d$freq)))
par(op)
？web.search.content
?web.search.content
require(Rweibo)
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1)$Weibo ##page参数请自己设置
#2.分词
require(Rwordseg)
insertWords("葡萄牙")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
#3.词云展示
require(wordcloud)
dd<-tail(d,150)
op<-par(bg="lightyellow")
#grayLevels<-gray((dd$freq)/(max(dd$freq)+140))
#wordcloud(dd$word,dd$freq,colors=grayLevels)
rainbowLevels<-rainbow((dd$freq)/(max(dd$freq)-10))
wordcloud(dd$word,dd$freq,col=rainbow(length(d$freq)))
par(op)
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since=2014-06-17)$Weibo ##page参数请自己设置
require(Rwordseg)
insertWords("葡萄牙")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
？wordcloud
?wordcloud
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since=2014-06-17)$Weibo ##page参数请自己设置
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since=2014-06-17)$Weibo ##page参数请自己设置
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since="2014-06-17")$Weibo ##page参数请自己设置
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since="2014-06-17")$Weibo ##page参数请自己设置
require(Rweibo)
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since="2014-06-17")$Weibo ##page参数请自己设置
require(Rwordseg)
insertWords("葡萄牙")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
write.csv("词频.csv")
write.csv(d,"词频.csv")
eibo)
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1, since="2014-06-17")$Weibo
#2.分词
require(Rwordseg)
insertWords("葡萄牙")
n<-length(res)
res<-res[res!=" "]
words<-unlist(lapply(X=res,FUN=segmentCN))
word=lapply(X=words,FUN=strsplit," ")
v=table(unlist(word))
v=sort(v,deceasing=T)
d=data.frame(word=names(v),freq=v)
#3.词云展示
require(wordcloud)
dd<-tail(d,150)
op<-par(bg="lightyellow")
#grayLevels<-gray((dd$freq)/(max(dd$freq)+140))
#wordcloud(dd$word,dd$freq,colors=grayLevels)
rainbowLevels<-rainbow((dd$freq)/(max(dd$freq)-10))
wordcloud(dd$word,dd$freq,col=rainbow(length(d$freq)))
par(op)
require(Rweibo)
require(Rwordseg)
res<-web.search.content("葡萄牙",page=50,sleepmean=10,sleepsd=1)$Weibo
setwd("worldcup_prediction")
library(knitr)
knit2html("worldcup_prediction.Rmd")
knit2html("worldcup_prediction.Rmd")
knit2html("worldcup_prediction.Rmd")
sessionInfo()
date
knit2html("worldcup_prediction.Rmd")
knit2html("worldcup_prediction.Rmd")
knit2html("worldcup_prediction.Rmd")
knit2html("worldcup_prediction.Rmd")
library(fmsb)
maxmin <- data.frame(
total=c(5,1),
phys=c(15,3),
psycho=c(3,0),
social=c(5,1),
env=c(5,1))
install.packages("fmsb")
library(fmsb)
maxmin <- data.frame(
total=c(5,1),
phys=c(15,3),
psycho=c(3,0),
social=c(5,1),
env=c(5,1))
radarchart(dat,axistype=1,seg=5,plty=1,title="(axis=1, 5 segments)")
dat <- data.frame()
dat <- rbind(maxmin,dat)
radarchart(dat,axistype=1,seg=5,plty=1,title="(axis=1, 5 segments)")
radarchart(dat,axistype=2,pcol=topo.colors(3),plty=1,title="(topo.colors, axis=2)")
library(fmsb)
maxmin <- data.frame(
total=c(5,1),
phys=c(15,3),
psycho=c(3,0),
social=c(5,1),
env=c(5,1))
# data for radarchart function version 1 series, minimum value must be omitted from above.
RNGkind("Mersenne-Twister")
set.seed(123)
dat <- data.frame(
total=runif(3,1,5),
phys=rnorm(3,10,2),
psycho=c(0.5,NA,3),
social=runif(3,1,5),
env=c(5,2.5,4))
dat <- rbind(maxmin,dat)
op <- par(mar=c(1,2,2,1),mfrow=c(2,2))
radarchart(dat,axistype=1,seg=5,plty=1,title="(axis=1, 5 segments)")
radarchart(dat,axistype=2,pcol=topo.colors(3),plty=1,title="(topo.colors, axis=2)")
radarchart(dat,axistype=3,pty=32,plty=1,axislabcol="grey",na.itp=FALSE,title="(no points, axis=3, na.itp=FALSE)")
radarchart(dat,axistype=0,plwd=1:5,pcol=1,title="(use lty and lwd but b/w, axis=0)")
par(op)
View(final_result_2010)
library(fmsb)
result_2010_1 <- data.frame(Won=final_result_2010[1,c(5,12)],
Draw=final_result_2010[1,c(6,13)],
Lost=final_result_2010[1,c(7,14)],
Goal_For=final_result_2010[1,c(8,15)],
Goal_Against=final_result_2010[1,c(8,15)])
RNGkind("Mersenne-Twister")
op <- par(mar=c(1,2,2,1),mfrow=c(2,2))
radarchart(result_2010_1,axistype=2,pcol=topo.colors(2),plty=1,
title="Argentina vs .Mexico")
library(fmsb)
result_2010_1 <- data.frame(Won=final_result_2010[2,c(5,12)],
Draw=final_result_2010[2,c(6,13)],
Lost=final_result_2010[2,c(7,14)],
Goal_For=final_result_2010[2,c(8,15)],
Goal_Against=final_result_2010[2,c(8,15)])
RNGkind("Mersenne-Twister")
op <- par(mar=c(1,2,2,1),mfrow=c(2,2))
View(result_2010_1)
Won=final_result_2010[1,c(5,12)]
View(Won)
result_2010_1 <- matrix(Won=final_result_2010[1,c(5,12)],
Draw=final_result_2010[1,c(6,13)],
Lost=final_result_2010[1,c(7,14)],
Goal_For=final_result_2010[1,c(8,15)],
Goal_Against=final_result_2010[1,c(8,15)])
